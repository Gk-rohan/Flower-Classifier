{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3458 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "                'training_set', target_size=(64, 64), batch_size=32, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Image processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 859 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "        'test_set',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dropout(0.5)) #just like another layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flattening\n",
    "cnn.add(tf.keras.layers.Flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hidden layer\n",
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu')) #128 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output layer\n",
    "cnn.add(tf.keras.layers.Dense(units=5, activation='softmax')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "109/109 [==============================] - 400s 4s/step - loss: 1.3257 - accuracy: 0.4286 - val_loss: 1.1078 - val_accuracy: 0.5471\n",
      "Epoch 2/10\n",
      "109/109 [==============================] - 292s 3s/step - loss: 1.0976 - accuracy: 0.5599 - val_loss: 1.1051 - val_accuracy: 0.5530\n",
      "Epoch 3/10\n",
      "109/109 [==============================] - 292s 3s/step - loss: 1.0044 - accuracy: 0.6105 - val_loss: 1.1556 - val_accuracy: 0.5937\n",
      "Epoch 4/10\n",
      "109/109 [==============================] - 294s 3s/step - loss: 0.9306 - accuracy: 0.6397 - val_loss: 1.0672 - val_accuracy: 0.5867\n",
      "Epoch 5/10\n",
      "109/109 [==============================] - 292s 3s/step - loss: 0.8702 - accuracy: 0.6666 - val_loss: 0.9175 - val_accuracy: 0.6484\n",
      "Epoch 6/10\n",
      "109/109 [==============================] - 290s 3s/step - loss: 0.8409 - accuracy: 0.6729 - val_loss: 1.0026 - val_accuracy: 0.6345\n",
      "Epoch 7/10\n",
      "109/109 [==============================] - 266s 2s/step - loss: 0.7925 - accuracy: 0.6952 - val_loss: 0.8700 - val_accuracy: 0.6659\n",
      "Epoch 8/10\n",
      "109/109 [==============================] - 273s 3s/step - loss: 0.7815 - accuracy: 0.7001 - val_loss: 0.8743 - val_accuracy: 0.6554\n",
      "Epoch 9/10\n",
      "109/109 [==============================] - 270s 2s/step - loss: 0.7302 - accuracy: 0.7233 - val_loss: 0.8969 - val_accuracy: 0.6694\n",
      "Epoch 10/10\n",
      "109/109 [==============================] - 273s 2s/step - loss: 0.6963 - accuracy: 0.7423 - val_loss: 0.8113 - val_accuracy: 0.7066\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xc23185bb20>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(x=training_set, validation_data= test_set, epochs=10)  #epochs === loops "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocess new images for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.preprocessing import image\n",
    "# test_image = tf.keras.utils.load_img('Prediction/t.jpg', target_size=(64, 64))\n",
    "# test_image = tf.keras.utils.img_to_array(test_image)\n",
    "# test_image = np.expand_dims(test_image, axis=0)\n",
    "# result = cnn.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if result[0][0]==1:\n",
    "#     print('Daisy')\n",
    "# elif result[0][1]==1:\n",
    "#     print('Dandelion')\n",
    "# elif result[0][2]==1:\n",
    "#     print('Rose')\n",
    "# elif result[0][3]==1:\n",
    "#     print('SunFlower')\n",
    "# elif result[0][4]==1:\n",
    "#     print(\"Tulip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(cnn,'my_model2.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "import streamlit as st \n",
    "from PIL import Image\n",
    "import tensorflow as tf \n",
    "from image_classifier import process_image, prediction_result\n",
    "import time\n",
    "\n",
    "st.set_option('deprecation.showfileUploaderEncoding', False)\n",
    "\n",
    "st.title(\"Flower Classifier\")\n",
    "\n",
    "st.write(\"This app can predict flowers from five categories: Daisy, Rose, Sunflower, Tulip and Dandelion\")\n",
    "st.write(\"Disclaimer: May not always give correct prediction!\")\n",
    "st.write(\"Made by: Rohan Gupta\")\n",
    "\n",
    "img = st.file_uploader(\"Please upload Image\", type=[\"jpeg\", \"jpg\", \"png\"])\n",
    "\n",
    "# Display Image\n",
    "st.write(\"Uploaded Image\")\n",
    "try:\n",
    "    img = Image.open(img)\n",
    "    st.image(img) # display the image\n",
    "    img = process_image(img)\n",
    "\n",
    "\n",
    "    # Prediction\n",
    "    model = tf.keras.models.load_model(\"my_model2.hdf5\")\n",
    "    prediction = prediction_result(model, img)\n",
    "\n",
    "\n",
    "    # Progress Bar\n",
    "    my_bar = st.progress(0)\n",
    "    for percent_complete in range(100):\n",
    "        time.sleep(0.05)\n",
    "        my_bar.progress(percent_complete + 1)\n",
    "\n",
    "    # Output\n",
    "    st.write(\"# Flower Type: {}\".format(prediction[\"class\"]))\n",
    "    st.write(\"With Accuracy:\", prediction[\"accuracy\"],\"%\")\n",
    "except AttributeError:\n",
    "    st.write(\"No Image Selected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting image_classifier.py\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "%%writefile image_classifier.py\n",
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "from PIL import Image, ImageOps\t\n",
    "import cv2\n",
    "\n",
    "\n",
    "def process_image(img, img_size=(64, 64)):\n",
    "  \"\"\"\n",
    "  This function is used to pre-process any chosen picture by the user\n",
    "  to the appropriate format that the model accepts.\n",
    "  Parameters:\n",
    "    img: The input Image, opened using the PIL library\n",
    "    img_size: Defaults to (64, 64) because it is the size that the \n",
    "              model accepts\n",
    "  Returns:\n",
    "    An Image array that is ready to be fed into the model.\n",
    "  \"\"\"\n",
    "  # reshapes the image\n",
    "  image = ImageOps.fit(img, img_size, Image.ANTIALIAS)\n",
    "  # converts the image into numpy array\n",
    "  image = np.asarray(image)\n",
    "  # converts image from BGR color space to RGB\n",
    "  img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "  img_resize = (cv2.resize(img, dsize=img_size, interpolation=cv2.INTER_CUBIC))/255.\n",
    "\n",
    "  img_reshape = img_resize[np.newaxis,...]\n",
    "  \n",
    "  return img_reshape\n",
    "\n",
    "\n",
    "def prediction_result(model, image_data):\n",
    "  \"\"\"\n",
    "  The function that returns the prediction result from the model\n",
    "  Parameters:\n",
    "    model: The model to be used to classify\n",
    "    image_data: Image array that is returned by the process_image function\n",
    "  \n",
    "  Returns --> Dictionary with class and accuracy values\n",
    "  \"\"\"\n",
    "  # Mapping prediction results to the Flower type\n",
    "  classes = {0: \"Daisy\", \n",
    "             1: \"Dandelion\",\n",
    "             2: \"Rose\",\n",
    "             3: \"Sunflower\",\n",
    "             4: \"Tulip\"}\n",
    "  \n",
    "  pred = model.predict(image_data)\n",
    "  pred = pred.round(2)\n",
    "  result = np.argmax(pred)\n",
    "  \n",
    "  prediction = {\"class\": classes[result],\n",
    "                \"accuracy\": np.round(np.max(pred) * 100, 2)}\n",
    "  \n",
    "  return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
